<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>requests 库 and 正则表达式 | 关关雎鸠</title><meta name="keywords" content="爬虫,Python"><meta name="author" content="烟柳画桥"><meta name="copyright" content="烟柳画桥"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本文简单的讲一下requests库的基本操作 requests库的安装首先确定你已经安装了requests库，如果没有的话 pip install requests 简单的使用请求可以这样写 import requestsr &#x3D; requests.get(&quot;http:&#x2F;&#x2F;www.baidu.com&quot;)  #对应GETdata &#x3D; &amp;#123;&amp;#x27;key&amp;#x27;:&amp;#">
<meta property="og:type" content="article">
<meta property="og:title" content="requests 库 and 正则表达式">
<meta property="og:url" content="http://example.com/2018/09/21/class1/index.html">
<meta property="og:site_name" content="关关雎鸠">
<meta property="og:description" content="本文简单的讲一下requests库的基本操作 requests库的安装首先确定你已经安装了requests库，如果没有的话 pip install requests 简单的使用请求可以这样写 import requestsr &#x3D; requests.get(&quot;http:&#x2F;&#x2F;www.baidu.com&quot;)  #对应GETdata &#x3D; &amp;#123;&amp;#x27;key&amp;#x27;:&amp;#">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">
<meta property="article:published_time" content="2018-09-21T08:35:33.000Z">
<meta property="article:modified_time" content="2019-08-11T12:46:38.759Z">
<meta property="article:author" content="烟柳画桥">
<meta property="article:tag" content="爬虫">
<meta property="article:tag" content="Python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2018/09/21/class1/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'requests 库 and 正则表达式',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2019-08-11 20:46:38'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">26</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">关关雎鸠</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">requests 库 and 正则表达式</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2018-09-21T08:35:33.000Z" title="发表于 2018-09-21 16:35:33">2018-09-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2019-08-11T12:46:38.759Z" title="更新于 2019-08-11 20:46:38">2019-08-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python/">Python</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python/%E7%88%AC%E8%99%AB/">爬虫</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="requests 库 and 正则表达式"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本文简单的讲一下requests库的基本操作</p>
<h2 id="requests库的安装"><a href="#requests库的安装" class="headerlink" title="requests库的安装"></a>requests库的安装</h2><p>首先确定你已经安装了requests库，如果没有的话</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>
<h2 id="简单的使用"><a href="#简单的使用" class="headerlink" title="简单的使用"></a>简单的使用</h2><p>请求可以这样写</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">&quot;http://www.baidu.com&quot;</span>)  <span class="comment">#对应GET</span></span><br><span class="line">data = &#123;<span class="string">&#x27;key&#x27;</span>:<span class="string">&#x27;value&#x27;</span>&#125;</span><br><span class="line">r = requests.post(<span class="string">&quot;http://www.baidu.com&quot;</span>,data=data)  <span class="comment">#对应POST 提交表单, data为表单数据，以字典型数据存储</span></span><br><span class="line"> <span class="comment">#主要前两种后面几乎用不到</span></span><br><span class="line">r = requests.put(<span class="string">&quot;http://www.baidu.com&quot;</span>)  <span class="comment">#对应PUT</span></span><br><span class="line">r = requests.delete(<span class="string">&quot;http://www.baidu.com&quot;</span>) <span class="comment">#对应删除DELETE</span></span><br><span class="line">r = requests.head(<span class="string">&quot;http://www.baidu.com&quot;</span>)   <span class="comment">#</span></span><br></pre></td></tr></table></figure>
<p>很方便的看出请求很简单，一行代码就可以完成请求，但是这只是一般网站的主页，我们肯定是要去其他部分提取信息的，所以会附加一大串的参数，比如</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r = requests.get(<span class="string">&#x27;http://httpbin.org/get?name=germey&amp;age=22&#x27;</span>)  </span><br></pre></td></tr></table></figure>
<h3 id="构造一些参数"><a href="#构造一些参数" class="headerlink" title="构造一些参数"></a>构造一些参数</h3><p>虽然也能完成任务，但翻页操作什么的每次都构造这个显然是不够好用，这个库当然不会让我们用这么笨的方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> age <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">50</span>):</span><br><span class="line">	params = &#123;</span><br><span class="line">		<span class="string">&quot;name&quot;</span> : <span class="string">&quot;germey&quot;</span>,</span><br><span class="line">		<span class="string">&quot;age&quot;</span> : age</span><br><span class="line">	&#125;</span><br><span class="line">	r = requests.get(<span class="string">&#x27;http://httpbin.org/get&#x27;</span>,params = params)</span><br><span class="line"></span><br><span class="line">成功完成附加参数的提交</span><br><span class="line">我们还可能遇到一个最low的反爬措施（知乎） 通过User-Agent 浏览器标识来反爬虫，这个我们可以构造headers轻易的破解，还有一些需要登陆才能操作的网站同样也可以通过构造headers</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;Cookie&#x27;</span> : <span class="string">&#x27;ABTEST=0|1534834504|v1; SNUID=1C3DF36DB3B6C05E33DD8DD8B303CE03; IPLOC=CN3201; SUID=AF8E41DF3E18960A000000005B7BB748; SUID=AF8E41DF2C18960A000000005B7BB748; SUV=00151DF1DF418EAF5B7BB74C32B4D814; weixinIndexVisited=1; ppinf=5|1534908615|1536118215|dHJ1c3Q6MToxfGNsaWVudGlkOjQ6MjAxN3x1bmlxbmFtZTo2OlBzeWNob3xjcnQ6MTA6MTUzNDkwODYxNXxyZWZuaWNrOjY6UHN5Y2hvfHVzZXJpZDo0NDpvOXQybHVJV0FROGwzSTFjYlg3M3Z1akxfd3prQHdlaXhpbi5zb2h1LmNvbXw; pprdig=xm9mkmMYDlvMRbH0pAjDEpcsEDCvoz3ORcB-9-lzvVhkxyM55AmN7NQJ8KU3Ei67B6DAqmo_DjyIu3NchvKgznUCthv3eMG2u_T1MhiMkJD7nV3HrDRKv0KVeNyQnt4Zl6D4y1v8SlHfHd-6aGhSCKW_NDIv_JqJmP-7eWQgsKw; sgid=22-36710215-AVt82MciatqU4SaMibG2iceyUs; sct=3; ppmdig=1534925103000000f514b9c5b91510b7cd851626696ec141; JSESSIONID=aaaGoZeH3bNXx-s9OFBvw; SL_GWPT_Show_Hide_tmp=1; SL_wptGlobTipTmp=1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Host&#x27;</span> : <span class="string">&#x27;weixin.sogou.com&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Upgrade-Insecure-Requests&#x27;</span> : <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span> : <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">requests.get(<span class="string">&#x27;http://weixin.sogou.com&#x27;</span>,headers = headers)</span><br><span class="line">当然也可以cookies = &#123;</span><br><span class="line">	<span class="string">&#x27;a&#x27;</span> : <span class="string">&#x27;a&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line">requests.get(<span class="string">&#x27;http://weixin.sogou.com&#x27;</span>,cookies = cookies)</span><br><span class="line">但显然直接复制更方便</span><br><span class="line">如果遇到反爬措施怎么更换代理呢，requests也有十分简单的方法，类似于上面的参数提交</span><br><span class="line">proxies = &#123;</span><br><span class="line">	<span class="string">&quot;http&quot;</span> : <span class="string">&quot;http:127.0.0.1:8080&quot;</span>,</span><br><span class="line">	<span class="string">&quot;https&quot;</span> : <span class="string">&quot;https://127.0.0.0:5555&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">r = requests.get(<span class="string">&#x27;http:www.zhihu.com&#x27;</span>,proxies=proxies) <span class="comment">#当然上面的代理是不能用的，你可以找国内哪些免费网站上寻找，或者自己维护一个代理池（从各大网站上爬取代理ip,验证其可用性保存在数据库备用），当然付费代理最为好用。</span></span><br><span class="line">还有一个超时操作的处理直接在末尾的timeout 参数赋值即可，如果你使用的是GET、OPTIONS、POST、PUT、PATCH 或者 DELETE，那么你可以通过 allow_redirects 参数禁用重定向处理：</span><br><span class="line">r = requests.get(<span class="string">&#x27;http://github.com&#x27;</span>, allow_redirects=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h3 id="常遇到的问题"><a href="#常遇到的问题" class="headerlink" title="常遇到的问题"></a>常遇到的问题</h3><p>遇到网络问题（如：DNS 查询失败、拒绝连接等）时，Requests 会抛出一个 ConnectionError 异常。</p>
<p>如果 HTTP 请求返回了不成功的状态码， Response.raise_for_status() 会抛出一个 HTTPError 异常。</p>
<p>若请求超时，则抛出一个 Timeout 异常。</p>
<p>若请求超过了设定的最大重定向次数，则会抛出一个 TooManyRedirects 异常。</p>
<p>所有Requests显式抛出的异常都继承自 requests.exceptions.RequestException 。<br>我们通过上面的设置，利用try except 函数可以容易的捕获这些错误<br>此外还有一些证书认证操作，比如12306,他们的证书没有被官方认证，所以爬取会报错，这个设置也很简单。把 verify 参数设置为False 即可，不过会提醒我们一个警告，我们可以选择忽略他，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests.packages <span class="keyword">import</span> urllib3</span><br><span class="line">urllib3.disable_warnings() </span><br><span class="line">response = requests.get(<span class="string">&#x27;https://www.12306.cn&#x27;</span>,verify=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>讲完了请求那么我们获取的数据怎么拿到呢。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r.status_code  <span class="comment">#获取响应码，判断自己是否成功访问网站</span></span><br><span class="line">r.text <span class="comment">#将源码转换为text格式</span></span><br><span class="line">r.encoding = <span class="string">&#x27;utf-8&#x27;</span>  <span class="comment"># 改变网页源码的编码格式，一般是gbk,或者utf-8</span></span><br><span class="line">r.url <span class="comment">#获取请求的网址</span></span><br><span class="line"><span class="built_in">type</span>(**) <span class="comment">#输出内容的格式，比如text,json ,dict</span></span><br><span class="line">r.json() <span class="comment">#可以发现，调用json(）方法，就可以将返回结果是 JSON 格式的字符串转化为字典dict</span></span><br><span class="line">r.content  <span class="comment">#图片、音频、视频这些文件本质上都是由二进制码组成的，由于有特定的保存格式和对应的解析方式， 我们才可以看到这些形形色色的多媒体 所以，想要抓取它们，就要拿到它们的二进制码</span></span><br></pre></td></tr></table></figure>
<h2 id="正则re"><a href="#正则re" class="headerlink" title="正则re"></a>正则re</h2><p>正则表达式是处理字符串的强大工具，它有向己特定的语法结构，有了它，实现字符串的检索、替换、匹配验证都不在话下当然,对于爬虫来说，有了它，从HTML 里提取想要的信息就非常方便了<br>可以在开源中国里练手，强大的在线匹配功能<a target="_blank" rel="noopener" href="http://tool.oschina.net/regex/">http://tool.oschina.net/regex/</a><br>正则不是python独有的，其他编程语言中也有，re库是整个正则表达式的实现，很方便实用。</p>
<h3 id="match"><a href="#match" class="headerlink" title="match()"></a>match()</h3><p>这个函数可以检测你的正则表达式是否能成功匹配数据，如果失败就返回None,代表匹配失败。举个栗子！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">re.match(pattern, string, flags=<span class="number">0</span>)  <span class="comment">#对应正则表达式，字符串，标识符</span></span><br><span class="line">栗子：</span><br><span class="line">	<span class="keyword">import</span> re</span><br><span class="line">	<span class="built_in">str</span> = <span class="string">&quot;Hello 123 456 World is a demo&quot;</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="built_in">len</span>(<span class="built_in">str</span>))</span><br><span class="line">	result = re.match(<span class="string">&#x27;^Hello\s\d\d\d\s\d&#123;3&#125;\s\w&#123;5&#125;&#x27;</span>,<span class="built_in">str</span>)</span><br><span class="line">	<span class="built_in">print</span>(result)</span><br><span class="line">	<span class="built_in">print</span>(result.span())</span><br><span class="line">	<span class="built_in">print</span>(result.group())</span><br></pre></td></tr></table></figure>
<p>我们的正则表达式以^作为开头，然后\s匹配空白字符，\d匹配数字,\d{3}代表匹配三个数字，\w{5},匹配字母数字或下划线共五个。我们运行一下发现匹配到了 Hello 123 456 World，调用group()获取匹配内容，span()获取匹配范围。match()函数有两个参数，1为正则，二为待匹配字符串。<br>如果我们想要得到某一具体内容怎么办呢，比如只想得到123。那么我们可以在正则表达式中用()把它括起来</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = re.match(<span class="string">&#x27;^Hello\s(\d+)\s\d&#123;3&#125;\s\w&#123;5&#125;&#x27;</span>,<span class="built_in">str</span>)</span><br><span class="line"><span class="built_in">print</span>(result.group(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>这样难免有点繁琐，我们使用通用匹配就很方便——.<em>(.可匹配除换行符之外的任意字符。</em>匹配无限次)完成上面的匹配，我们可以这样写</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = re.match(<span class="string">&#x27;^Hello.*demo&#x27;</span>,<span class="built_in">str</span>)</span><br><span class="line"><span class="built_in">print</span>(result.group())</span><br></pre></td></tr></table></figure>
<p>那么这样真的没有缺点吗，答案是否定的：比如你想得到123这个数字</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = re.match(<span class="string">&#x27;^Hello.*(\d+).*demo&#x27;</span>，<span class="built_in">str</span>)</span><br><span class="line"><span class="built_in">print</span>(result.group(<span class="number">1</span>))</span><br><span class="line">运行一下发现结果不如人意并不是我们想要的</span><br></pre></td></tr></table></figure>
<p>这里就涉及到贪婪和非贪婪的问题，.<em>会匹配尽可能多的字符（贪婪匹配），我们只需要简单的更改就能成功(加？)<br>.</em>? 是非贪婪匹配，匹配尽可能少的字符，到数字的前面时就默认停止匹配，从而让我们得到正确的结果<br>但这里需要注意，如果匹配的结果在字符串结尾，.*?就有可能匹配不到任何内容了，因为它<br>匹配尽可能少的字符 例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">content = <span class="string">&#x27;http://weibo.com/comment/KEraCN&#x27;</span></span><br><span class="line">result1 = re.match(<span class="string">&#x27;http.*?comment/(.*?)&#x27;</span>,content)</span><br><span class="line">result2 = re.match(<span class="string">&#x27;http.*?comment/(.*)&#x27;</span>,content)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;result1&quot;</span>,result1.group(<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;result2&#x27;</span>, result2.group(<span class="number">1</span>)) </span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">result1</span><br><span class="line">result2 KEraCN</span><br></pre></td></tr></table></figure>
<h3 id="修饰符"><a href="#修饰符" class="headerlink" title="修饰符"></a>修饰符</h3><p>正则表达式可以包含一些可选标志修饰符来控制匹配的模式 修饰符被指定为一个可选的标志。<br>我们改一下字符串 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">str</span> = <span class="string">&quot;Hello 123 456 \nWorld is a demo&quot;</span></span><br><span class="line">result = re.match(<span class="string">&#x27;^Hello.*demo&#x27;</span>,<span class="built_in">str</span>)</span><br><span class="line"><span class="built_in">print</span>(result.group())</span><br><span class="line">发现报错，未成功得到字符</span><br><span class="line">这是因为．匹配的是除换行符之外的任意字符，当遇到换行符时，.*?就不能匹配了，所以导致匹配失败这里只需加一个修饰符 re.S ，即可修正这个错误：</span><br><span class="line">result = re.match(<span class="string">&#x27;^Hello.*demo&#x27;</span>,<span class="built_in">str</span>,re.S)</span><br><span class="line">re.I  <span class="comment">#使匹配大小写不敏感</span></span><br><span class="line">re.S  <span class="comment">#使.匹配包括换行符在内的所有字符</span></span><br><span class="line">还有其他不常用，自己去查阅吧</span><br></pre></td></tr></table></figure>
<p>那么如果我们要匹配的字符包含.或者其他的特殊字符怎么办呢，比如匹配网址<a target="_blank" rel="noopener" href="http://www.baidu.com./">http://www.baidu.com。</a> 这个时候就要用到强大的转义字符了</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">content = <span class="string">&#x27;www.baidu.com&#x27;</span></span><br><span class="line">result = re.match(<span class="string">&#x27;www\.baidu\.com&#x27;</span>,content)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<h3 id="search"><a href="#search" class="headerlink" title="search()"></a>search()</h3><p>match()方法是从字符串的开头匹配，我们用它来提取信息显然不方便，更适合用来检测某个字符串是否符合规则，所以我们介绍search()-扫描整个字符串返回第一个成功匹配的结果，没找到则返回None.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">re.search(pattern, string, flags=<span class="number">0</span>) <span class="comment">#对应正则表达式，字符串，标识符</span></span><br><span class="line">栗子：</span><br><span class="line">	<span class="keyword">import</span> re</span><br><span class="line">	html = <span class="string">&#x27;&#x27;&#x27;&lt;div id = &#x27;song-list&#x27;&gt;</span></span><br><span class="line"><span class="string">	&lt;h2 class = &#x27;title&#x27;&gt;经典老歌&lt;/h2&gt;</span></span><br><span class="line"><span class="string">	&lt;p class =&#x27;introduction&#x27;&gt;</span></span><br><span class="line"><span class="string">	经典老歌列表&lt;/p&gt;</span></span><br><span class="line"><span class="string">	&lt;ul id =&#x27;list&#x27; class = &#x27;list-gruop&#x27;&gt;</span></span><br><span class="line"><span class="string">	&lt;li data-view =&#x27;2&#x27;&gt;一路有你&lt;/li&gt;</span></span><br><span class="line"><span class="string">	&lt;li data-view=&#x27;7&#x27;&gt;</span></span><br><span class="line"><span class="string">	&lt;a href=&#x27;/2.mp3&#x27; singer=&#x27;任贤齐&#x27;&gt;沧海一声笑&lt;/a&gt;</span></span><br><span class="line"><span class="string">	&lt;/li&gt;</span></span><br><span class="line"><span class="string">	&lt;li data-view = &#x27;4&#x27; class =&#x27;active&#x27;&gt;</span></span><br><span class="line"><span class="string">	&lt;a href=&#x27;/3.mp3&#x27; singer=&#x27;齐秦&#x27;&gt;往事随风&lt;/a&gt;</span></span><br><span class="line"><span class="string">	&lt;/li&gt;</span></span><br><span class="line"><span class="string">	&lt;li data-view=&#x27;6&#x27;&gt;&lt;a href=&#x27;/4.mp3&#x27; singer = &#x27;beyond&#x27;&gt;光辉岁月&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">	&lt;li data-view=&#x27;5&#x27;&gt;&lt;a href=&#x27;/5.mp3&#x27; singer = &#x27;陈慧琳&#x27;&gt;记事本&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">	&lt;li data-view=&#x27;5&#x27;</span></span><br><span class="line"><span class="string">	&lt;a href =&#x27;/6.mp3&#x27; singer=&#x27;邓丽君&#x27;&gt;但愿人长久&lt;/a&gt;</span></span><br><span class="line"><span class="string">	&lt;/li&gt;</span></span><br><span class="line"><span class="string">	&lt;/ul&gt;</span></span><br><span class="line"><span class="string">	&lt;/div&gt;&#x27;&#x27;&#x27;</span></span><br><span class="line">	result = re.search(<span class="string">&quot;&lt;li.*?active.*?singer=&#x27;(.*?)&#x27;&gt;(.*?)&lt;/a&gt;&quot;</span>,html,re.S)</span><br><span class="line">	<span class="built_in">print</span>(result.group(<span class="number">1</span>),result.group(<span class="number">2</span>))</span><br><span class="line">	&gt;&gt;&gt;齐秦 往事随风</span><br><span class="line">	result = re.search(<span class="string">&quot;&lt;li.*?singer=&#x27;(.*?)&#x27;&gt;(.*?)&lt;/a&gt;&quot;</span>,html,re.S)</span><br><span class="line">	<span class="built_in">print</span>(result.group(<span class="number">1</span>),result.group(<span class="number">2</span>))</span><br><span class="line">	&gt;&gt;&gt;任贤齐沧海一声笑</span><br></pre></td></tr></table></figure>
<h3 id="findall"><a href="#findall" class="headerlink" title="findall()"></a>findall()</h3><p>search方法只能返回一个值，显然不足以满足我们的需求，findall方法返回所有符合要求的字符串，以列表的形式存储。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">re.findall(pattern, string, flags=<span class="number">0</span>)</span><br><span class="line">html 同上</span><br><span class="line">results = re.findall(<span class="string">&#x27;&lt;li.*?href=&#x27;</span>(.*?)<span class="string">&#x27;.*?singer=&#x27;</span>(.*?)<span class="string">&#x27;&gt;(.*?)&lt;/a&gt;&#x27;</span>,html,re.S)</span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">	<span class="built_in">print</span>(result)</span><br><span class="line">	<span class="built_in">print</span>(result[<span class="number">0</span>],result[<span class="number">1</span>],result[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;自己运行吧</span><br></pre></td></tr></table></figure>
<h3 id="sub"><a href="#sub" class="headerlink" title="sub()"></a>sub()</h3><p>除了提取信息我们还可用用正则修改文本，这时候就用到了sub()方法。还以上面的为例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;html = re.sub(<span class="string">&#x27;&lt;a.*?&gt;|&lt;/a&gt;&#x27;</span>,<span class="string">&#x27;&#x27;</span>,html)</span><br><span class="line">	results = re.findall(<span class="string">&#x27;&lt;li.*?&gt;(.*?)&lt;/li&gt;&#x27;</span>,html,re.S)</span><br><span class="line">	<span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">		<span class="built_in">print</span>(result.strip())</span><br><span class="line">	&gt;&gt;&gt;自己运行吧</span><br></pre></td></tr></table></figure>
<h3 id="compile"><a href="#compile" class="headerlink" title="compile()"></a>compile()</h3><p>前面所讲的方法都是用来处理字符串的方法，最后再介绍一下 compile()方法，这个方法可以将<br>正则字符串编译成正则表达式对象，以便在后面的匹配中复用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re </span><br><span class="line">content = <span class="string">&#x27;2018-2-11 12:00&#x27;</span></span><br><span class="line">patten = re.<span class="built_in">compile</span>(<span class="string">&#x27;\d&#123;2&#125;:\d&#123;2&#125;&#x27;</span>)</span><br><span class="line">pattem.split(content)</span><br></pre></td></tr></table></figure>
<p>另外， compile()还可以传入修饰符，例如 re.S等修饰符，这样search(),findall()等方法中<br>就不需要额外传了 所以compile()方法可以说是给正则表达式做了一层封装，以使我们更好地复用</p>
<p>ok 扯淡完毕本节结束具体看实例吧</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">烟柳画桥</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2018/09/21/class1/">http://example.com/2018/09/21/class1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">关关雎鸠</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a><a class="post-meta__tags" href="/tags/Python/">Python</a></div><div class="post_share"><div class="social-share" data-image="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/gh/overtrue/share.js@master/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2018/10/13/k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">k近邻算法</div></div></a></div><div class="next-post pull-right"><a href="/2018/09/01/weixin/"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">反爬微信搜狗文章</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/05/17/class2/" title="解析库Beautiful-Soup"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-17</div><div class="title">解析库Beautiful-Soup</div></div></a></div><div><a href="/2018/08/29/elm/" title="饿了么爬虫尝试"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-08-29</div><div class="title">饿了么爬虫尝试</div></div></a></div><div><a href="/2018/11/26/pq/" title="Pyquery解析库"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-11-26</div><div class="title">Pyquery解析库</div></div></a></div><div><a href="/2018/09/01/weixin/" title="反爬微信搜狗文章"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-09-01</div><div class="title">反爬微信搜狗文章</div></div></a></div><div><a href="/2018/08/29/pyquery/" title="简单的爬虫"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-08-29</div><div class="title">简单的爬虫</div></div></a></div><div><a href="/2018/10/18/%E7%BD%91%E6%98%93%E4%BA%91%E8%AF%84%E8%AE%BA/" title="网易云音乐评论"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-10-18</div><div class="title">网易云音乐评论</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">烟柳画桥</div><div class="author-info__description">一蓑烟雨任平生，无畏西东</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">26</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#requests%E5%BA%93%E7%9A%84%E5%AE%89%E8%A3%85"><span class="toc-number">1.</span> <span class="toc-text">requests库的安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">2.</span> <span class="toc-text">简单的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%84%E9%80%A0%E4%B8%80%E4%BA%9B%E5%8F%82%E6%95%B0"><span class="toc-number">2.1.</span> <span class="toc-text">构造一些参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">2.2.</span> <span class="toc-text">常遇到的问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E5%88%99re"><span class="toc-number">3.</span> <span class="toc-text">正则re</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#match"><span class="toc-number">3.1.</span> <span class="toc-text">match()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E9%A5%B0%E7%AC%A6"><span class="toc-number">3.2.</span> <span class="toc-text">修饰符</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#search"><span class="toc-number">3.3.</span> <span class="toc-text">search()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#findall"><span class="toc-number">3.4.</span> <span class="toc-text">findall()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sub"><span class="toc-number">3.5.</span> <span class="toc-text">sub()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#compile"><span class="toc-number">3.6.</span> <span class="toc-text">compile()</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/05/17/class2/" title="解析库Beautiful-Soup"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="解析库Beautiful-Soup"/></a><div class="content"><a class="title" href="/2022/05/17/class2/" title="解析库Beautiful-Soup">解析库Beautiful-Soup</a><time datetime="2022-05-17T11:59:54.141Z" title="发表于 2022-05-17 19:59:54">2022-05-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/09/09/%E5%8A%9B%E6%89%A3-%E7%BF%BB%E8%BD%AC%E6%95%B0%E7%BB%84/" title="力扣题解—1"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="力扣题解—1"/></a><div class="content"><a class="title" href="/2021/09/09/%E5%8A%9B%E6%89%A3-%E7%BF%BB%E8%BD%AC%E6%95%B0%E7%BB%84/" title="力扣题解—1">力扣题解—1</a><time datetime="2021-09-09T05:33:08.000Z" title="发表于 2021-09-09 13:33:08">2021-09-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/09/08/%E8%BF%B7%E8%8C%AB%E7%9A%84%E7%8E%B0%E5%9C%A8/" title="迷茫的现在"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="迷茫的现在"/></a><div class="content"><a class="title" href="/2021/09/08/%E8%BF%B7%E8%8C%AB%E7%9A%84%E7%8E%B0%E5%9C%A8/" title="迷茫的现在">迷茫的现在</a><time datetime="2021-09-08T14:54:21.000Z" title="发表于 2021-09-08 22:54:21">2021-09-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2019/09/25/DosBox/" title="DosBox"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DosBox"/></a><div class="content"><a class="title" href="/2019/09/25/DosBox/" title="DosBox">DosBox</a><time datetime="2019-09-25T03:08:51.000Z" title="发表于 2019-09-25 11:08:51">2019-09-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2019/09/08/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="神经网络"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="神经网络"/></a><div class="content"><a class="title" href="/2019/09/08/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="神经网络">神经网络</a><time datetime="2019-09-08T03:20:09.000Z" title="发表于 2019-09-08 11:20:09">2019-09-08</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By 烟柳画桥</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>